{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Custom Kernel for latent forces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import gpjax as gpx\n",
    "import os\n",
    "import jax\n",
    "import matplotlib.pyplot as plt\n",
    "import jax.random as jr\n",
    "\n",
    "from dataclasses import dataclass, field\n",
    "\n",
    "from beartype.typing import Union\n",
    "import jax.numpy as jnp\n",
    "from jaxtyping import Float\n",
    "import tensorflow_probability.substrates.jax.bijectors as tfb\n",
    "import tensorflow_probability.substrates.jax.distributions as tfd\n",
    "\n",
    "from gpjax.base import param_field, static_field\n",
    "from gpjax.kernels.base import AbstractKernel\n",
    "from gpjax.kernels.stationary.utils import squared_distance\n",
    "from gpjax.typing import (\n",
    "    Array,\n",
    "    ScalarFloat,\n",
    ")\n",
    "\n",
    "from beartype.typing import Callable\n",
    "from jaxtyping import Int\n",
    "\n",
    "from p53_dataset import JAXP53_Data, load_barenco_data, flatten_dataset_jax\n",
    "jax.config.update('jax_enable_x64', True)\n",
    "\n",
    "from matplotlib import rcParams\n",
    "\n",
    "plt.style.use(\"https://raw.githubusercontent.com/JaxGaussianProcesses/GPJax/main/docs/examples/gpjax.mplstyle\")\n",
    "\n",
    "# Check if LaTeX is in notebook path\n",
    "if os.environ.get('PATH') is not None:\n",
    "    if 'TeX' not in os.environ['PATH']:\n",
    "        os.environ['PATH'] += os.pathsep + '/Library/TeX/texbin'\n",
    "\n",
    "colors = rcParams[\"axes.prop_cycle\"].by_key()[\"color\"]\n",
    "\n",
    "import tensorflow_probability.substrates.jax.bijectors as tfb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define basal transcription rate (B), transcript degradation rate (D), sensitivity of gene (S)\n",
    "def params_ground_truth():\n",
    "    B_exact = np.array([0.0649, 0.0069, 0.0181, 0.0033, 0.0869])\n",
    "    S_exact = np.array([0.9075, 0.9748, 0.9785, 1.0000, 0.9680])\n",
    "    D_exact = np.array([0.2829, 0.3720, 0.3617, 0.8000, 0.3573])\n",
    "    return B_exact, S_exact, D_exact\n",
    "\n",
    "# Define transcription rates measured by Barenco et al. (plotted points on GP graph)\n",
    "f_observed = np.array([0.1845,1.1785,1.6160,0.8156,0.6862,-0.1828, 0.5131])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data\n",
    "data_dir = os.path.join(os.getcwd(), '..', 'data')\n",
    "(original_genes_df, genes_transformed), (tfs_df, tfs_transformed), gene_var, tf_var, times = load_barenco_data(data_dir)\n",
    "\n",
    "p53_data = JAXP53_Data(replicate=3)\n",
    "train_t , train_y = flatten_dataset_jax(p53_data)\n",
    "\n",
    "# Set random key\n",
    "key = jr.PRNGKey(123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: move this to data class itself (?)\n",
    "\n",
    "num_genes = p53_data.num_outputs\n",
    "# (num_genes, dimension, num_timepoints)\n",
    "gene_data = jnp.array([p53_data[i] for i in range(num_genes)])\n",
    "\n",
    "time_points = gene_data[0,0,:]\n",
    "time_points_repeated = jnp.repeat(time_points, gene_data.shape[0])\n",
    "gene_indices = jnp.repeat(jnp.arange(gene_data.shape[0]), len(time_points))\n",
    "\n",
    "\n",
    "# Shape (t x j) x 3 where t is timepoints and j is genes\n",
    "training_times = jnp.stack((time_points_repeated, gene_indices, jnp.ones(num_genes * len(time_points), dtype=int)), axis=-1)\n",
    "\n",
    "\n",
    "# Shape (t x j) x 1 where t is timepoints and j is genes\n",
    "gene_expressions = gene_data[:,1,:].flatten().reshape(-1,1)\n",
    "\n",
    "dataset_train = gpx.Dataset(training_times, gene_expressions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100, 3)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Generate test points (t, i, 1):\n",
    "\n",
    "def gen_test_times(t=100):\n",
    "    \"\"\"\n",
    "    Generate testing times for the model of shape (N, 3) where N is the number of testing times. Default is N = 100\n",
    "    \"\"\"\n",
    "    times = jnp.linspace(0, 12, t)\n",
    "    # Gene indices shouldn't matter\n",
    "    gene_indices = jnp.repeat(-1, t)\n",
    "    testing_times = jnp.stack((times, gene_indices, jnp.repeat(0,t)), axis=-1)\n",
    "    return testing_times\n",
    "\n",
    "gen_test_times().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "testing_times = gen_test_times()\n",
    "\n",
    "train_row = dataset_train.X[20]\n",
    "test_row = testing_times[20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\ndef __call__(self, X: \\'Float[Array, \"1 D\"]\\', Xp: \\'Float[Array, \"1 D\"]\\') -> \\'Float[Array, \"1\"]\\':\\n    z = jnp.array(X[2], dtype=int)\\n    zp = jnp.array(Xp[2], dtype=int)\\n\\n    # Switches for different kernel functions\\n    kxx_switch = (1 - z) * (1 - zp)\\n    kff_switch = z * zp\\n    kxf_switch = (1 - z) * zp\\n    kxf_t_switch = z * (1 - zp)\\n\\n    # Compute the kernel value based on the switches\\n    result = (kxx_switch * self.kxx(X, Xp) +\\n                kff_switch * self.kff(X, Xp) +\\n                kxf_switch * self.kxf(X, Xp) +\\n                kxf_t_switch * self.kxf_transpose(X, Xp))\\n    return result\\n        \\n'"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "def __call__(self, X: 'Float[Array, \"1 D\"]', Xp: 'Float[Array, \"1 D\"]') -> 'Float[Array, \"1\"]':\n",
    "    z = jnp.array(X[2], dtype=int)\n",
    "    zp = jnp.array(Xp[2], dtype=int)\n",
    "\n",
    "    # Switches for different kernel functions\n",
    "    kxx_switch = (1 - z) * (1 - zp)\n",
    "    kff_switch = z * zp\n",
    "    kxf_switch = (1 - z) * zp\n",
    "    kxf_t_switch = z * (1 - zp)\n",
    "\n",
    "    # Compute the kernel value based on the switches\n",
    "    result = (kxx_switch * self.kxx(X, Xp) +\n",
    "                kff_switch * self.kff(X, Xp) +\n",
    "                kxf_switch * self.kxf(X, Xp) +\n",
    "                kxf_t_switch * self.kxf_transpose(X, Xp))\n",
    "    return result\n",
    "        \n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Kernel is element wise (i.e. rows)\n",
    "def kernel_switch_testing(X, Y):\n",
    "    \"\"\"\n",
    "    Testing switch implementation for kernel switching.\n",
    "\n",
    "    Parameters:\n",
    "    X: Row of input with shape (1, 3)\n",
    "    Y: Row of input withshape (1, 3)\n",
    "\n",
    "    Returns:\n",
    "        Integer\n",
    "    \"\"\"\n",
    " \n",
    "    f1 = jnp.array(X[2], dtype=int)\n",
    "    f2 = jnp.array(Y[2], dtype=int)\n",
    "    \n",
    "\n",
    "    kxx_switch = f1 * f2\n",
    "    kff_switch = (1 - f1) * (1 - f2)\n",
    "    kxf_switch = f1 * (1 - f2)\n",
    "    kxf_t_switch = (1 - f1) * f2\n",
    "\n",
    "    print(f'kxx: {kxx_switch}')\n",
    "    print(f'kff: {kff_switch}')\n",
    "    print(f'kxf: {kxf_switch}')\n",
    "    print(f'kfx: {kxf_t_switch}')\n",
    "\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GPJAX KERNEL IS ELEMENT WISE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Array(0.54132485, dtype=float32)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pos_constraint = tfb.Softplus()\n",
    "\n",
    "init_s = pos_constraint.inverse(1.0)\n",
    "init_s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "called\n",
      "H called\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "@dataclass\n",
    "class test_kernel(gpx.kernels.AbstractKernel):\n",
    "\n",
    "\n",
    "    def __call__(self, x: Float[Array, \" D\"], y: Float[Array, \" D\"]) -> ScalarFloat:\n",
    "\n",
    "        print('called')\n",
    "\n",
    "\n",
    "        h = self.h()\n",
    "        print(h)\n",
    "\n",
    "        return None\n",
    "    \n",
    "    def h(self):\n",
    "        print('H called')\n",
    "        return 1\n",
    "    \n",
    "test_ker = test_kernel()\n",
    "test_ker(2,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class p53_kxx(gpx.kernels.AbstractKernel):\n",
    "    r\"Covariance function of gene expressions j and k at time t and t'\"\n",
    "\n",
    "    name: str = 'kxx'\n",
    "\n",
    "    # TODO: review inverse initialisation method - check if init as list or single param\n",
    "    pos_constraint: Callable = tfb.Softplus()\n",
    "    initial_s: Float[Array, \" O\"] = static_field(pos_constraint.inverse(1.0))\n",
    "    initial_d: Float[Array, \" O\"] = static_field(pos_constraint.inverse(0.4))\n",
    "    \n",
    "    # Use dummy variables before trying inverse method\n",
    "    initial_s_test: Float[Array, \" O\"] = static_field(jnp.array([1.0]))\n",
    "    initial_d_test: Float[Array, \" O\"] = static_field(jnp.array([1.0]))\n",
    "\n",
    "    # Define sensitivities for both genes\n",
    "    s_j: Float[Array, \" O\"] = param_field(initial_s_test, bijector=pos_constraint)\n",
    "    s_k: Float[Array, \" O\"] = param_field(initial_s_test, bijector=pos_constraint)\n",
    "\n",
    "    # Define decay rates for both genes\n",
    "    d_j: Float[Array, \" O\"] = param_field(initial_d_test, bijector=pos_constraint)\n",
    "    d_k: Float[Array, \" O\"] = param_field(initial_d_test, bijector=pos_constraint)\n",
    "\n",
    "    # Use measured sensiivities and decays at first\n",
    "    #true_s: Float[Array, \"1 5\"] = static_field(jnp.array([0.9075, 0.9748, 0.9785, 1.0000, 0.9680]))\n",
    "    #true_d: Float[Array, \"1 5\"] = static_field(jnp.array([0.2829, 0.3720, 0.3617, 0.8000, 0.3573]))\n",
    "\n",
    "    true_s: Float[Array, \"1 5\"] = static_field(jnp.array([1.0,1.0,1.0,1.0,1.0]))\n",
    "    true_d: Float[Array, \"1 5\"] = static_field(jnp.array([0.4,0.4,0.4,0.4,0.4]))\n",
    "\n",
    "    # Use dummy lengthscale at first\n",
    "    l: Float[Array, \" O\"] = static_field(jnp.array([2.5]))\n",
    "    \n",
    "    \n",
    "    def __call__(self, t: Int[Array, \"1 3\"], t_prime: Int[Array, \"1 3\"]) -> ScalarFloat:\n",
    "        \"\"\"\n",
    "        Equation 5 in paper k_xx(t,t')\n",
    "        \"\"\"\n",
    "        # Error trap (JAX friendly)\n",
    "        def check_validity(condition):\n",
    "            if condition:\n",
    "                #raise ValueError(\"t or t' cannot be testing points (z=0)\")\n",
    "                return 0\n",
    "\n",
    "        condition = jnp.logical_or(t[2] == 0, t_prime[2] == 0)\n",
    "        jax.debug.callback(check_validity, condition)\n",
    "        \n",
    "        # Get gene indices\n",
    "        j = t[1].astype(int)\n",
    "        k = t_prime[1].astype(int)\n",
    "\n",
    "        \"\"\"\n",
    "        print('kxx has been called')\n",
    "        print(self.true_s)\n",
    "        print(self.true_d)\n",
    "        print(t.shape)\n",
    "        print(t_prime.shape)\n",
    "\n",
    "        print(f'lengthscale {self.l}, {type(self.l)}')\n",
    "        \"\"\"\n",
    "\n",
    "        # NOTE: using index yields same results\n",
    "        t = self.slice_input(t)\n",
    "        t_prime = self.slice_input(t_prime)\n",
    "\n",
    "\n",
    "        \"\"\"\n",
    "        print('Inputs have been sliced')\n",
    "        print(t, t.shape)\n",
    "        print(t, t_prime.shape)\n",
    "        \"\"\"\n",
    "\n",
    "        mult = self.true_s[j] * self.true_s[k] * self.l * jnp.sqrt(jnp.pi) * 0.5\n",
    "        second_term = self.h(k,j, t_prime, t) + self.h(j,k, t, t_prime)\n",
    "        \n",
    "\n",
    "        kxx = mult * second_term\n",
    "\n",
    "        \"\"\"\n",
    "        print(second_term.shape)\n",
    "        print(f'mult {mult}, shape: {mult.shape}')\n",
    "        print(f'second term {second_term}, shape: {second_term.shape}')\n",
    "\n",
    "        print(f'kxx shape {kxx.shape}')\n",
    "        \n",
    "\n",
    "        print(f'j index {j}, k index {k}')\n",
    "        print(f'time 1 {t}, time 2 {t_prime}')\n",
    "        print(f'sj {self.true_s[j]}, sk {self.true_s[k]}, dj {self.true_d[j]}, dk {self.true_d[k]}')\n",
    "        \"\"\"\n",
    "\n",
    "        return kxx.squeeze()\n",
    "        \n",
    "    \n",
    "    def h(self,j: Int[Array, \" O\"],k: Int[Array, \" O\"],t1: Int[Array, \" O\"],t2: Int[Array, \" O\"]) -> ScalarFloat:\n",
    "        \"\"\"\n",
    "        Analytical solution for the convolution of the exponential kernel with a step function.\n",
    "        \"\"\"\n",
    "\n",
    "        t_dist = t2-t1\n",
    "\n",
    "        multiplier = jnp.exp(self.gamma(k)**2) / (self.true_d[j] + self.true_d[k])\n",
    "\n",
    "        first_multiplier = jnp.exp(-self.true_d[k]*t_dist)\n",
    "        first_erf_terms = jax.scipy.special.erf((t_dist / self.l) - self.gamma(k)) + jax.scipy.special.erf(t1/self.l + self.gamma(k))\n",
    "\n",
    "        second_multiplier = jnp.exp(-(self.true_d[k]*t2 + self.true_d[j]*t1))\n",
    "        second_erf_terms = jax.scipy.special.erf((t2 / self.l) - self.gamma(k)) + jax.scipy.special.erf(self.gamma(k))\n",
    "\n",
    "        result = multiplier * (jnp.multiply(first_multiplier, first_erf_terms) - jnp.multiply(second_multiplier, second_erf_terms))\n",
    "\n",
    "        return result\n",
    "    \n",
    "    def gamma(self, k: Int[Array, \" O\"]) -> ScalarFloat:\n",
    "        # Gamma term for h function\n",
    "        return (self.true_d[k] * self.l) /2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class p53_kxf(gpx.kernels.AbstractKernel):\n",
    "    r\"Cross-covariance between gene expression j at time t and f at time t'\"\n",
    "\n",
    "    name: str = 'cross covariance'\n",
    "\n",
    "    # TODO: look at initialisation methods and sharing of parameters between covariances\n",
    "\n",
    "    # Use measured sensiivities and decays at first\n",
    "    true_s: Float[Array, \"1 5\"] = static_field(jnp.array([0.9075, 0.9748, 0.9785, 1.0000, 0.9680]))\n",
    "    true_d: Float[Array, \"1 5\"] = static_field(jnp.array([0.2829, 0.3720, 0.3617, 0.8000, 0.3573]))\n",
    "\n",
    "    true_s: Float[Array, \"1 5\"] = static_field(jnp.array([1.0,1.0,1.0,1.0,1.0]))\n",
    "    true_d: Float[Array, \"1 5\"] = static_field(jnp.array([0.4,0.4,0.4,0.4,0.4]))\n",
    "\n",
    "    # Use dummy lengthscale at first\n",
    "    l: Float[Array, \" O\"] = static_field(jnp.array([2.5]))\n",
    "\n",
    "    def __call__(self, t: Int[Array, \"1 3\"], t_prime: Int[Array, \"1 3\"]) -> ScalarFloat:\n",
    "\n",
    "        \"\"\"\n",
    "        # Error trap (JAX friendly)\n",
    "        def check_val_test(condition):\n",
    "            if condition:\n",
    "                #raise ValueError(\"t and t' cannot both be testing points (z=0)\")\n",
    "                return 0\n",
    "            \n",
    "        def check_val_train(condition):\n",
    "            if condition:\n",
    "                raise ValueError(\"t and t' cannot both be training points (z=1)\")\n",
    "                \n",
    "            \n",
    "        cond_test = jnp.logical_and(t[2] == 0, t_prime[2] == 0)\n",
    "        cond_train = jnp.logical_and(t[2] == 1, t_prime[2] == 1)\n",
    "\n",
    "        jax.debug.callback(check_val_test, cond_test)\n",
    "        jax.debug.callback(check_val_train, cond_train)\n",
    "        \"\"\"\n",
    "        \n",
    "        # Get gene expression and latent force from flag (kxf anf kfx are transposes)\n",
    "        gene_xpr = jnp.where(t[2] == 0, t_prime, t)\n",
    "        latent_force = jnp.where(t[2] == 0, t, t_prime)\n",
    "    \n",
    "        j = gene_xpr[1].astype(int)\n",
    "\n",
    "        #print(f'Latent force {latent_force}')\n",
    "        #print(f'Gene expression {gene_xpr}') \n",
    "\n",
    "        # Slice inputs\n",
    "        gene_xpr = self.slice_input(gene_xpr)\n",
    "        latent_force = self.slice_input(latent_force)\n",
    "\n",
    "        #print(f'Latent force {latent_force}')\n",
    "        #print(f'Gene expression {gene_xpr}')\n",
    "\n",
    "        t_dist = jnp.abs(gene_xpr - latent_force)   \n",
    "        \n",
    "        first_term = 0.5 * self.l * jnp.sqrt(jnp.pi) * self.true_s[j]\n",
    "        first_expon_term = jnp.exp(self.gamma(j)**2)\n",
    "        second_expon_term = jnp.exp(-self.true_d[j]*t_dist)\n",
    "        erf_terms = jax.scipy.special.erf((t_dist / self.l) - self.gamma(j)) + jax.scipy.special.erf(latent_force/self.l + self.gamma(j))\n",
    "\n",
    "        kxf = first_term * first_expon_term * second_expon_term * erf_terms\n",
    "        \n",
    "        \"\"\"\n",
    "        print(f'first_term {first_term}')\n",
    "        print(f'first_expon_term {first_expon_term}')\n",
    "        print(f'second_expon_term {second_expon_term}')\n",
    "        print(f'erf_terms {erf_terms}')\n",
    "        \"\"\"\n",
    "        \n",
    "        return kxf.squeeze()\n",
    "    \n",
    "    def gamma(self, k: Int[Array, \" O\"]) -> ScalarFloat:\n",
    "        # Gamma term for h function\n",
    "        return (self.true_d[k] * self.l) /2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class p53_combined_kernel(gpx.kernels.AbstractKernel):\n",
    "    r\"Combined covariance for learning the latent replication of p53\"\n",
    "\n",
    "    name: str = 'p53 Cov'\n",
    "\n",
    "    # Define external kernels\n",
    "    kernel_xx: gpx.kernels.AbstractKernel = field(default_factory=lambda: p53_kxx(active_dims=[0]))\n",
    "\n",
    "    kernel_xf: gpx.kernels.AbstractKernel = field(default_factory=lambda: p53_kxf(active_dims=[0]))\n",
    "\n",
    "    kernel_ff: gpx.kernels.AbstractKernel = field(default_factory=lambda: gpx.kernels.RBF(active_dims=[0]))\n",
    "    \n",
    "\n",
    "    def __call__(self, t: Int[Array, \"1 3\"], t_prime: Int[Array, \"1 3\"]) -> ScalarFloat:\n",
    "\n",
    "        # Get flag from input (1 = gene expression, 0 = latent force function)\n",
    "        f1 = jnp.array(t[2], dtype=int)\n",
    "        f2 = jnp.array(t_prime[2], dtype=int)\n",
    "\n",
    "        # Cannot use if statements in kernels -> use switches\n",
    "        kxx_switch = f1 * f2\n",
    "        kff_switch = (1 - f1) * (1 - f2)\n",
    "        kxf_switch = f1 * (1 - f2)\n",
    "        kxf_t_switch = (1 - f1) * f2\n",
    "\n",
    "        print(f'kxx: {kxx_switch}, kxx {self.kernel_xx(t, t_prime)}')\n",
    "        print(f'kff: {kff_switch}, kff {self.kernel_ff(t, t_prime)}')\n",
    "        print(f'kxf: {kxf_switch}, kxf {self.kernel_xf(t, t_prime)}')\n",
    "        print(f'kfx: {kxf_t_switch}, kxf_t {self.kernel_xf(t_prime, t)}')\n",
    "\n",
    "        final_kernel = kxx_switch * self.kernel_xx(t, t_prime) + kff_switch * self.kernel_ff(t, t_prime) + kxf_switch * self.kernel_xf(t, t_prime) + kxf_t_switch * self.kernel_xf(t_prime, t)\n",
    "\n",
    "        return final_kernel\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kxx: 0, kxx 0.6090426794825481\n",
      "kff: 0, kff 1.7745721988554163e-07\n",
      "kxf: 1, kxf 0.5956942675783378\n",
      "kfx: 0, kxf_t 0.5956942675783378\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Array(0.59569427, dtype=float64)"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p53_ker = p53_combined_kernel()\n",
    "p53_ker(train_row,test_row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 639,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Array([8., 2., 1.], dtype=float64)"
      ]
     },
     "execution_count": 639,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 640,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "first_term [2.21556731]\n",
      "first_expon_term [1.28402542]\n",
      "second_expon_term [0.10749585]\n",
      "erf_terms [1.94792912]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Array(0.59569427, dtype=float64)"
      ]
     },
     "execution_count": 640,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "k_xf = p53_kxf(active_dims=[0])\n",
    "k_xf(dataset_train.X[20],test_row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 641,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Array([8., 2., 1.], dtype=float64)"
      ]
     },
     "execution_count": 641,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 642,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(35, 3)"
      ]
     },
     "execution_count": 642,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kxx_ker = p53_kxx(active_dims=[0])\n",
    "t1 = dataset_train.X\n",
    "t1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 643,
   "metadata": {},
   "outputs": [],
   "source": [
    "arr_12 = jnp.array([12, 4, 1])\n",
    "arr_12t = jnp.array([12, 4, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 644,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Array(3.40952609, dtype=float64)"
      ]
     },
     "execution_count": 644,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kxx_ker(arr_12,arr_12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 645,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "first_term [2.21556731]\n",
      "first_expon_term [1.28402542]\n",
      "second_expon_term [1.]\n",
      "erf_terms [0.47950012]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Array(1.3641034, dtype=float64)"
      ]
     },
     "execution_count": 645,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kxf_ker = p53_kxf(active_dims=[0])\n",
    "kxf_ker(arr_12t,arr_12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 650,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "first_term [2.21556731]\n",
      "first_expon_term [1.28402542]\n",
      "second_expon_term [1.]\n",
      "erf_terms [0.47950012]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Array(1.3641034, dtype=float64)"
      ]
     },
     "execution_count": 650,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kxf_ker(arr_12t,arr_12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 586,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/project_wp289/lib/python3.11/site-packages/IPython/core/pylabtools.py:152: UserWarning: There are no gridspecs with layoutgrids. Possibly did not call parent GridSpec with the \"figure\" keyword\n",
      "  fig.canvas.print_figure(bytes_io, **kw)\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 480x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.matshow(kxx_ker.gram(t1).to_dense())\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(35, 3)"
      ]
     },
     "execution_count": 287,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# HOW TO PLOT KERNEL AND CHECK IT LOOKS OK?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 344,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 100\n",
    "noise = 0.3\n",
    "x_gpr = jr.uniform(key=key, minval=-3.0, maxval=3.0, shape=(n,)).reshape(-1, 1)\n",
    "f_gpr = lambda x: jnp.sin(4 * x) + jnp.cos(2 * x)\n",
    "\n",
    "kernel_gpr = gpx.kernels.RBF(active_dims=[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 548,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "()"
      ]
     },
     "execution_count": 548,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kernel_gpr(test_row, test_row).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SHOULD A GPJAX KERNEL RETURN ONE FOR IDENTICAL INPUTS?????"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 341,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Array([[-0.15513296,  0.        ],\n",
       "       [ 0.20999486,  0.        ],\n",
       "       [ 2.70871393,  0.        ],\n",
       "       [-0.24233199,  0.        ],\n",
       "       [ 0.62798972,  0.        ],\n",
       "       [-1.04605396,  0.        ],\n",
       "       [-0.29715902,  0.        ],\n",
       "       [ 0.89566759,  0.        ],\n",
       "       [-2.13326535,  0.        ],\n",
       "       [-1.59715151,  0.        ],\n",
       "       [ 0.02428609,  0.        ],\n",
       "       [ 1.92848615,  0.        ],\n",
       "       [ 1.6970173 ,  0.        ],\n",
       "       [-0.6035951 ,  0.        ],\n",
       "       [ 0.26813325,  0.        ],\n",
       "       [-0.25503812,  0.        ],\n",
       "       [ 2.57459184,  0.        ],\n",
       "       [-0.99307462,  0.        ],\n",
       "       [ 2.10230002,  0.        ],\n",
       "       [-1.58137953,  0.        ],\n",
       "       [ 1.57460624,  0.        ],\n",
       "       [ 0.12240851,  0.        ],\n",
       "       [-0.70544628,  0.        ],\n",
       "       [-1.86591987,  0.        ],\n",
       "       [-1.53468077,  0.        ],\n",
       "       [ 2.15706123,  0.        ],\n",
       "       [-1.70874549,  0.        ],\n",
       "       [-2.28593996,  0.        ],\n",
       "       [-0.66266154,  0.        ],\n",
       "       [ 0.61508803,  0.        ],\n",
       "       [ 2.17109311,  0.        ],\n",
       "       [ 0.2357363 ,  0.        ],\n",
       "       [ 1.01281358,  0.        ],\n",
       "       [ 0.2641702 ,  0.        ],\n",
       "       [ 2.81608552,  0.        ],\n",
       "       [ 1.65937594,  0.        ],\n",
       "       [ 0.90771755,  0.        ],\n",
       "       [ 0.575871  ,  0.        ],\n",
       "       [ 2.59903443,  0.        ],\n",
       "       [-0.10699546,  0.        ],\n",
       "       [-2.35179917,  0.        ],\n",
       "       [-2.08384883,  0.        ],\n",
       "       [-2.19956605,  0.        ],\n",
       "       [ 2.87842957,  0.        ],\n",
       "       [-1.59577327,  0.        ],\n",
       "       [-2.50404514,  0.        ],\n",
       "       [-2.93501159,  0.        ],\n",
       "       [-2.90492061,  0.        ],\n",
       "       [ 1.70862188,  0.        ],\n",
       "       [ 1.36790482,  0.        ],\n",
       "       [-1.4300857 ,  0.        ],\n",
       "       [-0.5245788 ,  0.        ],\n",
       "       [-0.43667227,  0.        ],\n",
       "       [-0.38118769,  0.        ],\n",
       "       [-0.79853644,  0.        ],\n",
       "       [-2.5947292 ,  0.        ],\n",
       "       [-0.77687526,  0.        ],\n",
       "       [-1.67737244,  0.        ],\n",
       "       [ 1.33946702,  0.        ],\n",
       "       [ 1.02414182,  0.        ],\n",
       "       [-1.3868861 ,  0.        ],\n",
       "       [ 1.37968158,  0.        ],\n",
       "       [-1.6194458 ,  0.        ],\n",
       "       [ 0.84857268,  0.        ],\n",
       "       [ 1.56640187,  0.        ],\n",
       "       [-0.41070465,  0.        ],\n",
       "       [-1.00654599,  0.        ],\n",
       "       [ 1.85781139,  0.        ],\n",
       "       [-1.81370437,  0.        ],\n",
       "       [-0.68089136,  0.        ],\n",
       "       [ 2.83650369,  0.        ],\n",
       "       [-0.55140034,  0.        ],\n",
       "       [-1.78634044,  0.        ],\n",
       "       [ 2.19685378,  0.        ],\n",
       "       [ 1.80444834,  0.        ],\n",
       "       [-1.11542926,  0.        ],\n",
       "       [ 2.69786122,  0.        ],\n",
       "       [-0.72118866,  0.        ],\n",
       "       [ 0.39203414,  0.        ],\n",
       "       [-1.37921512,  0.        ],\n",
       "       [-1.37504227,  0.        ],\n",
       "       [-1.23681397,  0.        ],\n",
       "       [ 0.14469467,  0.        ],\n",
       "       [-1.12270135,  0.        ],\n",
       "       [-0.33614141,  0.        ],\n",
       "       [-2.64589151,  0.        ],\n",
       "       [ 1.59492601,  0.        ],\n",
       "       [-1.10561629,  0.        ],\n",
       "       [ 2.42740041,  0.        ],\n",
       "       [ 0.62877862,  0.        ],\n",
       "       [-0.56280794,  0.        ],\n",
       "       [ 2.66521249,  0.        ],\n",
       "       [-0.13236756,  0.        ],\n",
       "       [ 1.7954025 ,  0.        ],\n",
       "       [-2.0609105 ,  0.        ],\n",
       "       [-1.19542842,  0.        ],\n",
       "       [-2.06575465,  0.        ],\n",
       "       [-0.34454231,  0.        ],\n",
       "       [ 0.14723158,  0.        ],\n",
       "       [-1.3484917 ,  0.        ]], dtype=float64)"
      ]
     },
     "execution_count": 341,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_gpr_new = jnp.stack((x_gpr.reshape(-1,), jnp.repeat(0, 100)), axis=-1)\n",
    "x_gpr_new\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 346,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Array(1., dtype=float64)"
      ]
     },
     "execution_count": 346,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kernel_gpr(x_gpr_new,x_gpr_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 384,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100, 3)"
      ]
     },
     "execution_count": 384,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testing_times.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 472,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kxx: 0\n",
      "kff: 0\n",
      "kxf: 1\n",
      "kfx: 0\n"
     ]
    }
   ],
   "source": [
    "kernel_switch_testing(train_row, test_row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.matshow(kxx_ker.gram)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "project_wp289",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
