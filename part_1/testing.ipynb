{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialise_gp(kernel, mean, dataset):\n",
    "    prior = gpx.gps.Prior(kernel=kernel, mean_function=mean)\n",
    "    likelihood = gpx.likelihoods.Gaussian(num_datapoints=dataset.n, obs_stddev=jnp.array([1.0e-3], dtype=jnp.float64))\n",
    "    posterior = prior * likelihood\n",
    "    return posterior\n",
    "\n",
    "# Define gp\n",
    "mean = gpx.mean_functions.Zero()\n",
    "kernel = gpx.kernels.RBF()\n",
    "posterior = initialise_gp(kernel, mean, p53_gpjax_dataset)\n",
    "\n",
    "# Define marginal log likelihood\n",
    "mll = jit(gpx.objectives.ConjugateMLL(negative=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "objective = gpx.objectives.ConjugateMLL(negative=True)\n",
    "\n",
    "opt_posterior, history = gpx.fit_scipy(\n",
    "    model=posterior,\n",
    "    objective=objective,\n",
    "    train_data=p53_gpjax_dataset,  # Ensure this is your GPJax Dataset instance\n",
    "    max_iters=1000,  # You can adjust this number as necessary\n",
    "    verbose=True,  # Set to True or False based on whether you want optimization details printed\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training model\n",
    "import optax\n",
    "from tqdm import tqdm\n",
    "from gpjax.objectives import ConjugateMLL as c_mll\n",
    "from jax import jit, value_and_grad\n",
    "\n",
    "neg_log_likelihood = lambda params: -c_mll(posterior, p53_gpjax_dataset)\n",
    "\n",
    "optimizer = optax.adam(learning_rate=0.01)\n",
    "opt_state = optimizer.init(params)\n",
    "\n",
    "\n",
    "objective_and_grad = jit(value_and_grad(neg_log_likelihood))\n",
    "\n",
    "\n",
    "num_iterations = 100\n",
    "for i in tqdm(range(num_iterations)):\n",
    "    loss, grads = objective_and_grad(params)\n",
    "    updates, opt_state = optimizer.update(grads, opt_state)\n",
    "    params = optax.apply_updates(params, updates)\n",
    "    \n",
    "    if i % 10 == 0:  # print loss every 10 iterations\n",
    "        print(f\"Iteration {i}: NLL = {loss}\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
